{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Carvana-image-masking-challenge.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giacomogreggio/computer-vision-project/blob/master/Carvana_image_masking_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "4Gx_XfiA44HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "CVkLjWuE44Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import keras\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, MaxPool2D, ZeroPadding2D, Cropping2D, Softmax, Add, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzMKhWQN44Hz",
        "colab_type": "text"
      },
      "source": [
        "**DATASET PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RHD0jjKa44H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_dir = os.path.join(\"train\")\n",
        "label_dir = os.path.join(\"train_masks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EYTtfuJa44IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ../input/carvana-image-masking-challenge/train_masks.csv.zip -d train_mask_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gwZtrvXL44IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ../input/carvana-image-masking-challenge/train.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LIkPmOLk44IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ../input/carvana-image-masking-challenge/train_masks.zip -d train_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1zhgETN744Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('./train_mask_csv/train_masks.csv')\n",
        "ids_train = df_train['img'].map(lambda s: s.split('.')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0xUsZNEi44If",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = '/kaggle/working/'\n",
        "\n",
        "@tf.function\n",
        "def normalize(input_image):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image\n",
        "\n",
        "@tf.function\n",
        "def read_train_image(name, dataset_path):\n",
        "    image = cv2.imread(dataset_path + 'train/train/' + name + '.jpg',1)\n",
        "    resized_image = tf.image.resize(image, (256, 256), preserve_aspect_ratio=True)\n",
        "    return normalize(resized_image)\n",
        "\n",
        "@tf.function\n",
        "def read_mask(name, dataset_path):\n",
        "    image = np.array(Image.open(dataset_path + 'train_mask/train_masks/' + name + \"_mask.gif\"))\n",
        "    expanded_image = np.expand_dims(image, axis=-1)\n",
        "    resized_image = tf.image.resize(expanded_image, (256,256), preserve_aspect_ratio=True)\n",
        "    return tf.reshape(resized_image, (171,256))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4H-h9cv344Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_filenames = []\n",
        "y_train_filenames = []\n",
        "names = []\n",
        "for img_id in ids_train:\n",
        "    x_train_filenames.append('/kaggle/working/train/' + os.path.join(img_dir, \"{}.jpg\".format(img_id)))\n",
        "    y_train_filenames.append('/kaggle/working/train_mask/' + os.path.join(label_dir, \"{}_mask.gif\".format(img_id)))\n",
        "    names.append(img_id)\n",
        "dataset = []\n",
        "string_x = []\n",
        "string_y = []\n",
        "targets = []\n",
        "for i in range(0,10):\n",
        "    dataset.append(read_train_image(names[i], dataset_path))\n",
        "    string_x.append(x_train_filenames[i])\n",
        "for i in range(0,10):    \n",
        "    targets.append(read_mask(names[i], dataset_path))\n",
        "    string_y.append(y_train_filenames[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pW7eJqvC44Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = names[:101]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B3m_73tG44Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_examples = len(x_train_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ltXaz6nU44I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "display_num = 5\n",
        "\n",
        "r_choices = np.random.choice(num_train_examples, display_num)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "for i in range(0, display_num * 2, 2):\n",
        "  img_num = r_choices[i // 2]\n",
        "  x_pathname = x_train_filenames[img_num]\n",
        "  y_pathname = y_train_filenames[img_num]\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 1)\n",
        "  plt.imshow(mpimg.imread(x_pathname))\n",
        "  plt.title(\"Original Image\")\n",
        "  \n",
        "  example_labels = Image.open(y_pathname)\n",
        "  label_vals = np.unique(example_labels)\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 2)\n",
        "  plt.imshow(example_labels)\n",
        "  plt.title(\"Masked Image\")\n",
        "  \n",
        "plt.suptitle(\"Examples of Images and their Masks\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MBmJEXv444I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(Sequence):\n",
        "    \"\"\"Generates data for Keras\n",
        "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_IDs, dataset_path,\n",
        "                 to_fit=True, batch_size=32, dim=(256, 256),\n",
        "                 n_channels=1, n_classes=10, shuffle=True):\n",
        "        self.list_IDs = list_IDs\n",
        "        self.dataset_path=dataset_path\n",
        "        self.to_fit = to_fit\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\n",
        "        :return: number of batches per epoch\n",
        "        \"\"\"\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data\n",
        "        :param index: index of the batch\n",
        "        :return: X and y when fitting. X only when predicting\n",
        "        \"\"\"\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X = self._generate_X(list_IDs_temp)\n",
        "\n",
        "        if self.to_fit:\n",
        "            y = self._generate_y(list_IDs_temp)\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\n",
        "        \"\"\"\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _generate_X(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size images\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch of images\n",
        "        \"\"\"\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            X[i,] = read_train_image(ID, self.dataset_path)\n",
        "        return X\n",
        "\n",
        "    def _generate_y(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size masks\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch if masks\n",
        "        \"\"\"\n",
        "        y = np.empty((self.batch_size, *self.dim), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            y[i] = read_mask(ID,self.dataset_path) \n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cCBWl94a44JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = DataGenerator(names, dataset_path= '/kaggle/working/',\n",
        "                 to_fit=True, batch_size=20, dim=(171, 256),\n",
        "                 n_channels=3, n_classes=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SWGNqAeq44JI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SHAPE=(None,None,3)\n",
        "N_CLASSES=2\n",
        "L2_VALUE=5**-4\n",
        "\n",
        "BATCH_SIZE = 20 #128\n",
        "BUFFER_SIZE = 1000\n",
        "EPOCHS = 20 #500\n",
        "VAL_SUBSPLITS = 5\n",
        "\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "  display_list[1] = np.expand_dims(display_list[1],axis=2)\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]\n",
        "\n",
        "\n",
        "def show_predictions(num=1):\n",
        "  for i in range(num if num < len(dataset) else len(dataset)):  \n",
        "    n = len(dataset)-i-1\n",
        "    pred_mask = create_mask(model(np.expand_dims(dataset[i],axis=0)))\n",
        "    display([dataset[n], targets[n], pred_mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrNCjsgi44JM",
        "colab_type": "text"
      },
      "source": [
        "**USEFUL METHODS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y-FEz3Io44JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_output_shape(input_layer, last_layer):\n",
        "  return np.array(Model(input_layer, last_layer).layers[-1].output_shape[1:])\n",
        "\n",
        "def calculate_crop_value(output_shape, size_to_crop):\n",
        "    pixel_difference=output_shape-size_to_crop\n",
        "\n",
        "    half_height_left=int(pixel_difference[0]/2)\n",
        "    half_height_right=math.ceil(pixel_difference[0]/2)\n",
        "    half_width_left=int(pixel_difference[1]/2)\n",
        "    half_width_right=math.ceil(pixel_difference[1]/2)\n",
        "\n",
        "    return tuple([tuple([half_height_left,half_height_right]),tuple([half_width_left,half_width_right])])\n",
        "\n",
        "class Crop(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    x1, x2 = inputs\n",
        "    x1_shape = tf.shape(x1)\n",
        "    x2_shape = tf.shape(x2)\n",
        "    # offsets for the top left corner of the crop\n",
        "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
        "    size = [-1, x2_shape[1], x2_shape[2], -1]\n",
        "    x1_crop = tf.slice(x1, offsets, size)\n",
        "    return x1_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCmzJZCa44JT",
        "colab_type": "text"
      },
      "source": [
        "**VGG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IgURmpP244JU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_base_vgg(trainable=True):\n",
        "  #Defining Base VGG architecture\n",
        "  input_layer = Input(shape=IMAGE_SHAPE, name=\"input\")\n",
        "  #VGG-block1\n",
        "  b1 = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", name=\"conv2d_b1_1\")(input_layer)\n",
        "  b1 = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", name=\"conv2d_b1_2\")(b1)\n",
        "  b1 = MaxPool2D(pool_size=(2,2),strides=(2,2), name=\"maxpool_b1\")(b1)\n",
        "\n",
        "  #VGG-block2\n",
        "  b2 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b2_1\")(b1)\n",
        "  b2 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b2_2\")(b2)\n",
        "  b2 = MaxPool2D(pool_size=(2,2),strides=(2,2), name=\"maxpool_b2\")(b2)\n",
        "\n",
        "  #VGG-block3\n",
        "  b3 = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b3_1\")(b2)\n",
        "  b3 = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b3_2\")(b3)\n",
        "  b3 = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b3_3\")(b3)\n",
        "  b3 = MaxPool2D(pool_size=(2,2),strides=(2,2), name=\"maxpool_b3\")(b3)\n",
        "\n",
        "  #VGG-block4\n",
        "  b4 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b4_1\")(b3)\n",
        "  b4 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b4_2\")(b4)\n",
        "  b4 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b4_3\")(b4)\n",
        "  b4 = MaxPool2D(pool_size=(2,2),strides=(2,2), name=\"maxpool_b4\")(b4)\n",
        "\n",
        "  #VGG-block5\n",
        "  b5 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b5_1\")(b4)\n",
        "  b5 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b5_2\")(b5)\n",
        "  b5 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"conv2d_b5_3\")(b5)\n",
        "  b5 = MaxPool2D(pool_size=(2,2),strides=(2,2), name=\"maxpool_b5\")(b5)\n",
        "\n",
        "  vgg_model = Model(input_layer, b5)\n",
        "  vgg16= VGG16(weights=\"imagenet\", include_top=False)\n",
        "  vgg16.save_weights(\"./weights.h5\")\n",
        "  vgg_model.load_weights(\"./weights.h5\")\n",
        "  vgg_model.trainable=trainable\n",
        "\n",
        "  return vgg_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLKXk5i344JY",
        "colab_type": "text"
      },
      "source": [
        "**FCN-32**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YOp0PbhM44JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_fcn32(vgg_trainable=True, include_top=True):\n",
        "  vgg_model=create_base_vgg(trainable=vgg_trainable)\n",
        "  b5=vgg_model.layers[-1].output\n",
        "  input_layer=vgg_model.layers[0].output\n",
        "  fcn_32_block = Conv2D(4096, kernel_size=(7,7), activation='relu', padding=\"same\", kernel_regularizer=l2(L2_VALUE), name=\"conv2d_fcn32_1\")(b5)\n",
        "  fcn_32_block = Dropout(0.5, name=\"dropout_fcn32_1\")(fcn_32_block)\n",
        "  fcn_32_block = Conv2D(4096, kernel_size=(1,1), activation='relu', padding=\"same\", kernel_regularizer=l2(L2_VALUE), name=\"conv2d_fcn32_2\")(fcn_32_block)\n",
        "  fcn_32_block = Dropout(0.5, name=\"dropout_fcn32_2\")(fcn_32_block)\n",
        "  fcn_32_block = Conv2D(N_CLASSES, kernel_size=(1,1), padding=\"same\", kernel_regularizer=l2(L2_VALUE), name=\"conv2d_fcn32_3\")(fcn_32_block)\n",
        "  if include_top:\n",
        "    fcn_32_transpose = Conv2DTranspose(N_CLASSES, kernel_size=(64,64), strides=(32,32), kernel_regularizer=l2(L2_VALUE), use_bias=False, name=\"deconv_fcn32\")(fcn_32_block)\n",
        "    fcn_32_crop = Crop([fcn_32_transpose, input_layer])\n",
        "    fcn_32_softmax=Softmax(name=\"softmax_fcn32\")(fcn_32_crop)\n",
        "    return Model(input_layer, fcn_32_softmax)\n",
        "  else:\n",
        "    return Model(input_layer, fcn_32_block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWv4jwyz44Jc",
        "colab_type": "text"
      },
      "source": [
        "**FCN-16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n4VOjKxG44Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_fcn16(vgg_trainable=True, include_top=True):\n",
        "  fcn_32=create_fcn32(vgg_trainable=vgg_trainable, include_top=False)\n",
        "  input_layer=fcn_32.layers[0].output\n",
        "  b4=fcn_32.get_layer(\"maxpool_b4\").output\n",
        "  fcn_32_block=fcn_32.layers[-1].output\n",
        "\n",
        "  fcn_16_block_fcn32 = Conv2DTranspose(N_CLASSES, kernel_size=(4,4), padding=\"valid\", strides=(2,2), kernel_regularizer=l2(L2_VALUE), use_bias=False, name=\"deconv_fcn16_1\")(fcn_32_block)\n",
        "  fcn_16_block = Conv2D(N_CLASSES, kernel_size=(1,1), activation=\"relu\", kernel_regularizer=l2(L2_VALUE), padding=\"valid\", name=\"conv2d_fcn16_1\")(b4)\n",
        "\n",
        "  fcn_16_block_fcn32 = Crop()([fcn_16_block_fcn32,fcn_16_block])\n",
        "\n",
        "  fcn_16_block = Add(name=\"add_fcn16\")([fcn_16_block_fcn32,fcn_16_block])\n",
        "\n",
        "  if include_top:\n",
        "    fcn_16_deconv = Conv2DTranspose(N_CLASSES, kernel_size=(32,32), strides=(16,16), kernel_regularizer=l2(L2_VALUE), use_bias=False, name=\"deconv_fcn16_2\")(fcn_16_block)\n",
        "    fcn_16_crop = Crop()([fcn_16_deconv,input_layer])\n",
        "    fcn_16_softmax=Softmax(name=\"softmax_fcn16\")(fcn_16_crop)\n",
        "    return Model(input_layer, fcn_16_softmax)\n",
        "  else:\n",
        "    return Model(input_layer, fcn_16_block)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlzHXfXz44Jh",
        "colab_type": "text"
      },
      "source": [
        "**FCN-8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yjgPbExj44Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_fcn8(vgg_trainable=True, include_top=True):\n",
        "  fcn_16=create_fcn16(vgg_trainable=vgg_trainable, include_top=False)\n",
        "  input_layer=fcn_16.layers[0].output\n",
        "  b3=fcn_16.get_layer(\"maxpool_b3\").output\n",
        "  fcn_16_block=fcn_16.layers[-1].output\n",
        "\n",
        "  fcn_8_block_fcn16 = Conv2DTranspose(N_CLASSES, kernel_size=(4,4), padding=\"valid\", strides=(2,2), kernel_regularizer=l2(L2_VALUE), use_bias=False, name=\"deconv_fnc8_1\")(fcn_16_block)\n",
        "  fcn_8_block = Conv2D(N_CLASSES, kernel_size=(1,1), activation=\"relu\", kernel_regularizer=l2(L2_VALUE), padding=\"valid\", name=\"conv2d_fcn8_1\")(b3)\n",
        "\n",
        "  \n",
        "  fcn_8_block_fcn16 = Crop()([fcn_8_block_fcn16,fcn_8_block])\n",
        "  \n",
        "  fcn_8_block = Add(name=\"add_fcn8\")([fcn_8_block_fcn16,fcn_8_block])\n",
        "\n",
        "  if include_top:\n",
        "    fcn_8_deconv = Conv2DTranspose(N_CLASSES, kernel_size=(16,16), strides=(8,8), kernel_regularizer=l2(L2_VALUE), use_bias=False, name=\"deconv_fnc8_2\")(fcn_8_block)\n",
        "    fcn_8_crop = Crop()([fcn_8_deconv,input_layer])\n",
        "    fcn_8_softmax=Softmax(name=\"softmax_fcn8\")(fcn_8_crop)\n",
        "    return Model(input_layer, fcn_8_softmax)\n",
        "  else:\n",
        "    return Model(input_layer, fcn_8_block)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axRV0YkN44Jm",
        "colab_type": "text"
      },
      "source": [
        "**CALLBACKS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gmS368Mu44Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "75BiUwwB44Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class print_lr(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(\"Current Learning rate : {}\".format(self.model.optimizer.lr.numpy()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YmnE5V0P44Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaptedMeanIoU(tf.keras.metrics.Metric):\n",
        "  def __init__(self, name='mean_iou', N_CLASSES=3,**kwargs):\n",
        "    super(AdaptedMeanIoU, self).__init__(name=name, **kwargs)\n",
        "    self.mean_iou=MeanIoU(N_CLASSES)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred_converted=tf.argmax(y_pred,axis=-1)\n",
        "    self.mean_iou.update_state(y_true,y_pred_converted)\n",
        "  def result(self):\n",
        "    return self.mean_iou.result()\n",
        "  def reset_states(self):\n",
        "    self.mean_iou.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8fkpJX4q44Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, min_lr=1**-10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rCQPVz1X44J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks=[\n",
        "    keras.callbacks.EarlyStopping(patience=10),\n",
        "    keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True),\n",
        "    DisplayCallback(),\n",
        "    reduce_lr, \n",
        "    print_lr()\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tQZvB_4y44J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=create_fcn8()\n",
        "model.compile(optimizer=SGD(learning_rate=0.1, momentum=0.9, clipnorm=1), loss=SparseCategoricalCrossentropy(), metrics=[AdaptedMeanIoU(N_CLASSES=3)])\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5uioCNyr44J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = int(np.ceil(len(names) / float(BATCH_SIZE)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Yk8tILS344KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_predictions(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1Q0geLbi44KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_history = model.fit(generator, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          callbacks=[DisplayCallback(),reduce_lr, print_lr()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YtI_ybDf44KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "US87-Nxi44KL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_ds, \n",
        "                   steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),\n",
        "                   epochs=epochs,\n",
        "                   validation_data=val_ds,\n",
        "                   validation_steps=int(np.ceil(num_val_examples / float(batch_size))),\n",
        "                   callbacks=[cp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5BOybMDV44KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BXX6PriY44KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}